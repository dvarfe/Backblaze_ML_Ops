# Backblaze MLOps

## Текущее состояние системы
| Этап/Подэтап                          | Статус                                                                 |
|---------------------------------------|-----------------------------------------------------------------------|
| **0. Сбор данных**                    | ✅                                                                   |
|   1. Разделение потока на батчи (1 б.)| ✅                                                                   |
|   2. Хранилище - ФС (1 б.)            | ✅                                                                   |
|   3. Конфигурационный файл JSON(1 б.) | ✅                                                                   |
| **1. Анализ данных**                  | ✅                                                                   |
|   1. Оценка показателей данных(1/2 б.)  | +-                                                                   |
|   2. Очистка данных(1 б.)                   | ✅                                                                   |
| **2. Подготовка данных**              | ✅                                                                   |
|   1. Обработка пропусков(1 б.)              | ✅                                                                   |
|   2. Обработка категориальных переменных(1 б.) | ✅                                                                |
|   3. Обработка числовых переменных(1 б.)    | ✅                                                                   |
| **3. Обучение модели**                |                                                                      |
|   1. Обучение(1 б.)                         | ✅                                                                   |
|   2. Дообучение(1 б.)                       | ✅                                                                   |
| **4. Валидация модели**               |                                                                      |
|   1. Оценка модели на holdout(1 б.)         | ✅                                                                   |
|   2. Хранилище версий моделей         | +-                                                                   |
| **5. Обслуживание модели**            |                                                                      |
|   1. Сериализация модели(1 б.)              | ✅                                                                   |
| **6. Управление**                      |                                                                      |
|   1. Поддержка аргументов командной строки | ❌                                                               |
|   2. Документация                     | +-                                                                   |
|   3. Общий конфиг                     | ❌                                                                   |
|   4. MVC                              | ✅                                                                   |

## Установка

1. Клонировать репозиторий:

    ```bash
    git clone git@github.com:dvarfe/Backblaze_ML_Ops.git
    ```

2. Для установки зависимостей потребуется `pipenv`:

    ```bash
    pipenv install [-d]
    ```

    Флаг `-d` установит зависимости, используемые для разработки.

## Запуск программы

Запуск интерактивной консоли:

```bash
python disk_analyzer
```

## Основные команды

### collect_data

Сбор данных из указанных путей `path1, path2...` с разбиением на батчи размера `batchsize`.  
Собранные данные сохраняются в папке `storage_path`. Для передачи параметров через конфигурационный файл укажите `cfg_path`.

**Конфигурационный файл (JSON-формат):**

```json
{
    "batchsize": <размер батча>,
    "paths": [<список путей к данным>]
}
```

**Синтаксис:**

```bash
collect_data [path1 path2 ...] [-b BATCHSIZE] [-s STORAGE_PATH] [-c CFG_PATH]
```

**Пример:**

```bash
collect_data /Data/Sources/1 /Data/Sources/2 -b 100000 -s ./Data/Data_collected
```

---

### data_stats

Расчет различных статистик по данным. Результаты сохраняются в `figpath`.

**Синтаксис:**

```bash
data_stats -s [STATIC_STATS] -d [DYNAMIC_STATS] -f FIGPATH -q FREQ
```

**Параметры:**

- `-s`: Список статических метрик (например, `размер набора данных, количество пропусков`)
- `-d`: Список динамических метрик (например, `доля отказавших дисков в каждый день`)
- `-f`: Путь для сохранения графиков динамических статистик
- `-q`: Частота агрегации (`daily`/`monthly`)

---

### set_mode

Переключение режима фильтрации данных:

- `date`: Фильтрация по дате (формат: `YYYY-MM-DD`)
- `batch`: Фильтрация по номеру батча (целое число)

**Синтаксис:**

```bash
set_mode <mode>
```

**Пример:**

```bash
set_mode batch
```

---

### set_borders

Установка временных или числовых границ данных. Формат зависит от текущего режима.

**Синтаксис:**

```bash
set_borders <start> <end>
```

**Примеры:**

```bash
set_borders 2023-01-01 2023-12-31  # Режим 'date'
set_borders 100 200                 # Режим 'batch'
```

---

### rebatch

Изменение размера батча собранных данных.

**Синтаксис:**

```bash
rebatch <new_batchsize>
```

**Пример:**

```bash
rebatch 500
```

---

### preprocess

Подготовка данных для обучения моделей, включая разделение на обучающую (train) и тестовую (test) выборки.  
Поддерживает инкрементальное обновление выборок при поступлении новых данных.

**Синтаксис:**

```bash
preprocess [path_to_data]
```

**Логика работы:**

1. Данные из `storage_path` разделяются на train/test с учетом стратификации по классам.
2. Если обнаружены диски, переставшие быть truncated:
   - Их наблюдения добавляются в соответствующие выборки
   - Сохраняется баланс классов

---

### fit

Обучение моделей машинного обучения. Доступные модели:

- `logistic_regression`
- `nnet` (нейронная сеть, недоступна на текущий момент)
- `svm` (метод опорных векторов, недоступен на текущий момент)

**Синтаксис:**

```bash
fit <model_name>
```

**Пример:**

```bash
fit logistic_regression
```

---

### predict

Прогнозирование целевой переменной для предобработанных данных по указанному пути.  
Требуется предварительно обученная модель.

**Синтаксис:**

```bash
predict <path_to_data>
```

**Параметры:**

- `path_to_data`: Путь к данным для прогнозирования (файл или директория)

**Пример:**

```bash
predict ./test_data/2023_report.csv
```

**Примечания:**

1. Перед использованием команды необходимо обучить модель через `fit`.
2. Формат входных данных должен соответствовать формату, использованному при обучении.
3. Результаты прогноза выводятся в консоль и сохраняются в `<storage_path>/predictions`.

## Структура проекта

```
Backblaze_ML_Ops
├── Data/                     # Исходные/обработанные данные (не в репозитории)
├── disk_analyzer/
│   ├── controller/                # Логика управления процессами
│   │   └── __init__.py
│   ├── models/                    # Реализация моделей машинного обучения
│   │   └── DLClassifier.py
│   ├── stages/                    # Этапы обработки данных
│   │   ├── __init__.py
│   │   ├── data_collector.py
│   │   ├── data_preprocessor.py
│   │   ├── data_stats.py
│   │   └── model_pipeline.py
│   ├── utils/                     # Вспомогательные модули
│   │   └── constants.py
│   ├── view/                      # Визуализация возвращаемых значений модели
│   │   ├── __pycache__/
│   │   └── __init__.py
│   └── __init__.py
├── tests/                    # Тесты
├── main.py                   # Точка входа в приложение
├── Pipfile                   # Файл зависимостей (pipenv)
└── test.py                   # Скрипт для запуска тестов
```

## Документация

Для работы с документацией используется **Sphinx**.  
Чтобы сгенерировать HTML-документацию:

```bash
cd docs
make clean  # Очистка предыдущей сборки (опционально)
make html   # Генерация HTML
```

Точка входа — файл `index.html`.

## Реализованный функционал

1. Сбор данных с использованием ФС и конфигурационного файла.
2. Получение статистик данных.
3. Предобработка данных.
4. Построение модели.
5. Использование обученной модели.

## Планы на будущее

1. Поддержка аргументов командной строки.
2. Добавление двух других моделей.
3. Реализация дообучения модели.
4. Валидация модели на hold-out выборке.
5. Разработка хранилища моделей.
